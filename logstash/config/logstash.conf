input {
	tcp {
		port => 5000
	}
        udp {
	    port => 1514
	    type => "syslog"
    }
  }
    filter {
        syslog_pri {
            add_field => { "[@metadata][type]" => "syslog" }
            add_field => { "[@metadata][beat]" => "syslog" }
        }

    if [type] == "syslog" {
        # production access.log processing
        grok {
            match => [
                "message",
                '<190>%{SYSLOGTIMESTAMP:timestamp} %{NOTSPACE:node_name} %{HTTPDUSER:ident}: (?:%{IP:http_x_forwarded_for}|-) \[%{IP:remote_addr}\] - (?:%{USER:remote_user}|-) \[%{HTTPDATE:time_local}\] "%{IPORHOST:httphost}" "(?:%{WORD:verb} %{NOTSPACE:request})(?: HTTP/%{NUMBER:httpversion})" %{NUMBER:response_code} %{NUMBER:request_length} (?:%{NUMBER:bytes_sent}|-) (?:%{NUMBER:request_time}|-) %{QS:http_device} %{QS:http_user_agent}'
            ]
            break_on_match => true
            add_tag => [ "nginx_access_log", "prod" ]
            remove_tag => [ "_grokparsefailure" ]
        }

        # production error.log processing
        grok {
            match => [
            "message",
            '%{SYSLOGTIMESTAMP:timestamp} %{NOTSPACE:node_name} %{HTTPDUSER:ident}: %{GREEDYDATA:error}host: "%{IPORHOST:httphost}"'
            ]
                add_tag => [ "nginx_error_log", "prod", "error" ]
        }

        grok {
            match => [
                "message",
            '%{SYSLOGTIMESTAMP:timestamp} %{NOTSPACE:node_name} %{HTTPDUSER:ident}: %{GREEDYDATA:error}'
            ]
            add_tag => [ "nginx_error_log", "prod", "error" ]
        }

      } 
}

## Add your filters / logstash plugins configuration here

output {
	elasticsearch {
		hosts => "elasticsearch:9200"
                index =>"logstash-%{+YYYY.MM.dd}"
	}
}

